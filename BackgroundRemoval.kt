package com.hisham.removebg

import android.graphics.Bitmap
import android.graphics.Color
import ai.onnxruntime.OnnxTensor
import ai.onnxruntime.OrtEnvironment
import ai.onnxruntime.OrtSession
import java.util.Collections

object BackgroundRemoval {

    /**
     * Preprocess the given bitmap:
     * - Resize to the model input size (1024x1024)
     * - Normalize pixel values: (pixel/255 - 0.5)
     * - Convert the image into a CHW float array.
     */
    private fun preprocessBitmap(bitmap: Bitmap, inputWidth: Int, inputHeight: Int): FloatArray {
        val resizedBitmap = Bitmap.createScaledBitmap(bitmap, inputWidth, inputHeight, true)
        val width = resizedBitmap.width
        val height = resizedBitmap.height
        val pixels = IntArray(width * height)
        resizedBitmap.getPixels(pixels, 0, width, 0, 0, width, height)
        // Create a float array for 3 channels (CHW)
        val floatArray = FloatArray(3 * width * height)
        for (y in 0 until height) {
            for (x in 0 until width) {
                val pixel = pixels[y * width + x]
                val r = Color.red(pixel)
                val g = Color.green(pixel)
                val b = Color.blue(pixel)
                // Normalize: value/255, then subtract 0.5 (std is 1.0 so no division)
                val nr = r / 255.0f - 0.5f
                val ng = g / 255.0f - 0.5f
                val nb = b / 255.0f - 0.5f
                val index = y * width + x
                // Store in CHW order.
                floatArray[index] = nr                    // Red channel
                floatArray[width * height + index] = ng     // Green channel
                floatArray[2 * width * height + index] = nb   // Blue channel
            }
        }
        return floatArray
    }

    /**
     * Create a grayscale mask bitmap from a 1D float array.
     * The array is assumed to be of length (inputWidth*inputHeight)
     * with values in [0, 1]. Values are clipped, scaled to 0-255, and
     * used to form an ALPHA_8 bitmap.
     */
    private fun createMaskFromOutput(outputBuffer: FloatArray, maskWidth: Int, maskHeight: Int): Bitmap {
        val maskBitmap = Bitmap.createBitmap(maskWidth, maskHeight, Bitmap.Config.ALPHA_8)
        for (y in 0 until maskHeight) {
            for (x in 0 until maskWidth) {
                val index = y * maskWidth + x
                val value = outputBuffer[index]
                // Clip value between 0 and 1, then scale to 0-255
                val clipped = value.coerceIn(0f, 1f)
                val grayscale = (clipped * 255).toInt().coerceIn(0, 255)
                maskBitmap.setPixel(x, y, Color.argb(grayscale, grayscale, grayscale, grayscale))
            }
        }
        return maskBitmap
    }

    /**
     * Merge the original image with the given mask to create a new image where
     * the mask is used as the alpha channel.
     */
    fun mergeImageWithMask(original: Bitmap, mask: Bitmap): Bitmap {
        val width = original.width
        val height = original.height
        val outputBitmap = Bitmap.createBitmap(width, height, Bitmap.Config.ARGB_8888)
        for (y in 0 until height) {
            for (x in 0 until width) {
                val origPixel = original.getPixel(x, y)
                // Use the maskâ€™s red channel (mask is grayscale) as the alpha value.
                val alpha = Color.red(mask.getPixel(x, y))
                val newPixel = (alpha shl 24) or (origPixel and 0x00FFFFFF)
                outputBitmap.setPixel(x, y, newPixel)
            }
        }
        return outputBitmap
    }

    /**
     * Main background removal function.
     *
     * @param modelPath The file path to the ONNX model.
     * @param inputBitmap The original image as a Bitmap.
     * @return A Pair containing:
     *         - The merged image (original with background removed, via alpha channel)
     *         - The mask Bitmap generated by the model.
     */
    fun removeBackground(modelPath: String?, inputBitmap: Bitmap): Pair<Bitmap?, Bitmap?> {
        if (modelPath == null) return Pair(null, null)

        // Define the expected input size for the model.
        val inputWidth = 1024
        val inputHeight = 1024

        try {
            // Create the ONNX Runtime environment and session.
            val env = OrtEnvironment.getEnvironment()
            val sessionOptions = OrtSession.SessionOptions()
            val session = env.createSession(modelPath, sessionOptions)

            // Preprocess the image to get a normalized CHW float array.
            val inputData = preprocessBitmap(inputBitmap, inputWidth, inputHeight)
            val shape = longArrayOf(1, 3, inputHeight.toLong(), inputWidth.toLong())

            // Create an ONNX Tensor from the input data.
            val tensor = OnnxTensor.createTensor(env, inputData, shape)

            // Run inference.
            val inputName = session.inputNames.iterator().next()
            val results = session.run(Collections.singletonMap(inputName, tensor))
            // Assume output is of shape [1, 1, 1024, 1024]
            val outputTensor = results[0].value as Array<Array<Array<FloatArray>>>
            // Get the first batch and first channel output.
            val mask2D = outputTensor[0][0]  // shape: [1024][1024]
            // Flatten the 2D array into a 1D float array.
            val outputBuffer = FloatArray(inputWidth * inputHeight)
            for (y in 0 until inputHeight) {
                for (x in 0 until inputWidth) {
                    outputBuffer[y * inputWidth + x] = mask2D[y][x]
                }
            }

            // Create a grayscale mask Bitmap from the output.
            val maskBitmap = createMaskFromOutput(outputBuffer, inputWidth, inputHeight)
            // Resize the mask back to the original image dimensions.
            val resizedMask = Bitmap.createScaledBitmap(maskBitmap, inputBitmap.width, inputBitmap.height, true)
            // Merge the original image with the mask (using the mask as the alpha channel).
            val mergedBitmap = mergeImageWithMask(inputBitmap, resizedMask)

            // Clean up resources.
            tensor.close()
            results.forEach { it.close() }
            session.close()
            env.close()

            return Pair(mergedBitmap, resizedMask)
        } catch (e: Exception) {
            e.printStackTrace()
            return Pair(null, null)
        }
    }
}
